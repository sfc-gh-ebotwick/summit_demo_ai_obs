{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "lastEditStatus": {
   "notebookId": "5dle7ba5hpnnnzvkfmod",
   "authorId": "1784583909336",
   "authorName": "MLAPPS",
   "authorEmail": "garett.tok@snowflake.com",
   "sessionId": "24f366d7-865c-48f2-aaf3-36752500ab4c",
   "lastEditTime": 1743523659059
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d45331-c62b-4bb5-b947-77971382483a",
   "metadata": {
    "collapsed": false,
    "name": "Step5"
   },
   "source": [
    "## Step 5: Create RAG Application Classes\n",
    "\n",
    "In this step, we will create two Python classes to build a Retrieval-Augmented Generation (RAG) pipeline:\n",
    "\n",
    "1. **`CortexSearchRetriever`**:\n",
    "   - This class interacts with the Cortex Search Service to retrieve relevant contextual information based on a user query.\n",
    "   - It connects to the Cortex Search Service using Snowflake's `Root` object and performs a search with the specified query and result limit.\n",
    "   - The retrieved context (a list of relevant chunks) will be used to generate prompts for LLMs.\n",
    "\n",
    "2. **`RAGWithObservability`**:\n",
    "   - This class integrates the retrieval functionality with a specified Large Language Model (LLM) to complete the RAG pipeline.\n",
    "   - It uses the retriever to fetch context, creates a structured prompt by combining the context with the user query, and generates a response using the Snowflake Cortex `COMPLETE` function.\n",
    "   - The class allows testing of different LLMs (e.g., `llama3.1-8b`, `mistral-7b`, `claude-3-5-sonnet`) by specifying the desired model.\n",
    "    - In the below cells you'll notice an **@instrument** decorator above each function in our RAGWithObservability class\n",
    "    - This tells Trulens which stages of our application we want to track so we can understand how data flows through our application\n",
    "    - For example if our query takes 10s to run - what portion of that 10s was spent on retrieval? On prompt augmentation? On completion generation?\n",
    "        - This becomes increasingly important for complex GenAI applications (i.e. multi-agent apps)\n",
    "    - After we pass prompts through our trulens recorder we will inspect these traces and spans!\n",
    "\n",
    "### Workflow Summary:\n",
    "1. The `CortexSearchRetriever` retrieves relevant context from the Cortex Search Service.\n",
    "2. The `RAGWithObservability` uses this context to create prompts and generate responses with the specified LLM.\n",
    "\n",
    "These two classes work together to streamline the RAG pipeline, enabling efficient retrieval and response generation for various use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf34a-f360-4223-bff2-60f016ff6c3e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "CortexSearchRetrieverCell"
   },
   "outputs": [],
   "source": [
    "# Define the retriever class for interacting with the Cortex Search Service\n",
    "\n",
    "# Complete the missing code (???) to:\n",
    "## Specify your database 'SKO_SKORAGHOP_LIVE_PROD', your schema 'HOP', and your Cortex Search Service named 'RAG_SEARCH_SERVICE'\n",
    "## Specify your SEARCH_COL as the column of interest\n",
    "## Intialize retriever with your CortexSearchRetriever class\n",
    "## Use \"What are some components of the Snowflake Cortex offering? How do they work?\" for the test_query\n",
    "\n",
    "from typing import List\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.core import Root\n",
    "\n",
    "# CortexSearchRetriever\n",
    "class CortexSearchRetriever:\n",
    "    def __init__(self, session: Session, limit_to_retrieve: int = 4):\n",
    "        self._session = session\n",
    "        self._limit_to_retrieve = limit_to_retrieve\n",
    "        \n",
    "\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        root = Root(session)\n",
    "        cortex_search_service = (\n",
    "            root\n",
    "            .databases[\"SKO_SKORAGHOP_LIVE_PROD\"]\n",
    "            .schemas[\"HOP\"]\n",
    "            .cortex_search_services[\"RAG_SEARCH_SERVICE\"]\n",
    "        )\n",
    "        resp = cortex_search_service.search(\n",
    "            query=query,\n",
    "            columns=[\"SEARCH_COL\"],\n",
    "            limit=self._limit_to_retrieve,\n",
    "        )\n",
    "        return [row[\"SEARCH_COL\"] for row in resp.results] if resp.results else []\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = CortexSearchRetriever(session=session, limit_to_retrieve=3)\n",
    "test_query = \"What are some components of the Snowflake Cortex offering? How do they work?\"\n",
    "retrieved_context = retriever.retrieve(query=test_query)\n",
    "print(retrieved_context)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9a349f73-1e07-49dc-8a9d-492626503e01",
   "metadata": {
    "language": "python",
    "name": "set_trulens_OTEL_env_var"
   },
   "outputs": [],
   "source": "import os\nos.environ[\"TRULENS_OTEL_TRACING\"] = \"1\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b51fe4-118c-437c-a348-462d2fb25f58",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "DefineRAGClass"
   },
   "outputs": [],
   "source": "# Create the RAGWithObservability class to structure the RAG pipeline\nfrom snowflake.cortex import complete\nfrom trulens.core.otel.instrument import instrument\nfrom trulens.otel.semconv.trace import SpanAttributes\n\n\nclass RAGWithObservability():\n    def __init__(self, llm_model, retriever):\n        self.llm_model = llm_model\n        self.retriever = retriever\n        \n#Here we're using the @instrument decorator to trace various stages of our RAG applicaiton\n    @instrument (\n        span_type=SpanAttributes.SpanType.RETRIEVAL, \n        attributes={\n            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n        })  \n    def retrieve_context(self, query: str) -> List[str]:\n        return self.retriever.retrieve(query)\n\n    @instrument()\n    def augment_prompt(self, query: str, contexts: list) -> str:\n     \n        prompt = f\"\"\"\n        You are an expert assistant extracting information from context provided.\n        Answer the question based on the context. Be concise and do not hallucinate.\n        If you don't have the information, just say so.\n        Context: {' '.join(contexts)}\n        Question: {query}\n        Answer:\n        \"\"\"\n        return prompt\n\n\n    @instrument (span_type=SpanAttributes.SpanType.GENERATION)    \n    def generate_completion(self, query: str):\n        \n        df_response = complete(self.llm_model, query)\n        return df_response\n\n\n    @instrument (\n        span_type=SpanAttributes.SpanType.RECORD_ROOT, \n        attributes={\n            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n        })\n    def query_app(self, query: str) -> str:\n        contexts = self.retrieve_context(query)\n        prompt = self.augment_prompt(query, contexts)\n        final_response = self.generate_completion(prompt)\n        return final_response"
  },
  {
   "cell_type": "code",
   "id": "8467e565-8611-49e3-b259-b53c21a9f7ff",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "import streamlit as st\n\n#Define LLM classes\nllama_rag = RAGWithObservability('llama3.1-8b', retriever)\nmistral7b_rag = RAGWithObservability('mistral-7b', retriever)\nclaude_rag = RAGWithObservability('claude-3-5-sonnet', retriever)\n\n#print Query\nprint(f\"Query: {test_query}\")\n\n#Get and print responses\nllama_response = llama_rag.query_app(test_query)\nst.write(f\"**Llama response** -  {llama_response} \\n\")\n\nmistral_response = mistral7b_rag.query_app(test_query)\nst.write(f\"**Mistral-7b response** - {mistral_response} \\n\")\n\nclaude_response = claude_rag.query_app(test_query)\nst.write(f\"**Claude response** -  {claude_response} \\n\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5b33b25-20c3-4cd7-9dce-118400be593c",
   "metadata": {
    "collapsed": false,
    "name": "Step6"
   },
   "source": "## Step 6: Observe and Evaluate LLM Performance with AI Observability (powered by TruLens)\n\n**Adding Observability and Evaluataion to our RAG application**\n\nHere, we enhance the Retrieval-Augmented Generation (RAG) process by introducing observability. Observability ensures that LLM responses can be measured and evaluated based on various feedback metrics, providing insights into the model's performance and areas for improvement.\n\n**How This Works**\n\nWe will use a feature called AI Observability to register our recently created applications in Snowflake. This will allow users to pass in prompts to these applications, and trace each step the application takes to Retrieve appropriate context, Augment a system prompt with additional context and Generate a complete answer for the given prompt. \n\nFrom there we will use LLM-as-a-Judge based evaluations to measure LLM performance based on **feedback metrics** including:\n- **Answer Relevance** - Evaluates how directly the LLM's response addresses the user's prompt.\n- **Context Relevance** - Assesses the relevance of the retrieved context to the user's prompt.\n- **Groundedness**  - Measures how well the LLM's response is anchored in the retrieved context.\n- **Coherance** - Evaluates how logically structured and easy to follow the LLM's response is."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13d6db-55d3-4841-8915-1088cab39a45",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "AIObservability"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/AIObservability.jpg\", decompress=False).read() \n",
    "\n",
    "# Display the image\n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58d853-417c-4d46-abfd-6c928613a45f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "LLMObservabilitySetup"
   },
   "outputs": [],
   "source": "# from trulens.core import TruSession\nfrom trulens.apps.app import TruApp\nfrom trulens.connectors.snowflake import SnowflakeConnector\n\ntru_snowflake_connector = SnowflakeConnector(snowpark_session=session)\n\napp_name = \"test_sko_app_update\"\nversion_num = 'v0'\n\ntru_rag_mistral = TruApp(\n    mistral7b_rag,\n    app_name=app_name,\n    app_version=f\"mistral_test_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_llama = TruApp(\n    llama_rag,\n    app_name=app_name,\n    app_version=f\"llama_test_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_claude = TruApp(\n    claude_rag,\n    app_name=app_name,\n    app_version=f\"claude_test_{version_num}\",\n    connector=tru_snowflake_connector\n)"
  },
  {
   "cell_type": "code",
   "id": "239dd11c-5b9a-40f9-a115-39692c06ed05",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "import pandas as pd\n\nprompts = [\n    \"What are some metrics to measure the quality of a retrieval system?\",\n    \"Can I have a back-and-forth conversation with Cortex?\",\n    \"Does Snowflake support text-to-sql? What services would support this?\",\n    \"What year was the war of 1812?\",\n    \"Tell me a story about Snowflake Cortex\"\n]\n\n\nbatch_data = pd.DataFrame({'QUERY': prompts})\nbatch_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e86306d7-b0a9-4d12-af47-f881228d7d9d",
   "metadata": {
    "language": "python",
    "name": "define_run_configs"
   },
   "outputs": [],
   "source": "from trulens.core.run import Run\nfrom trulens.core.run import RunConfig\n\nmistral_run_config = RunConfig(\n    run_name=f\"mistral_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"MISTRAL\",\n    llm_judge_name = \"llama3.1-70b\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n)\n\n\n\nllama_run_config = RunConfig(\n    run_name=f\"llama_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LLAMA\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)\n\n\nclaude_run_config = RunConfig(\n    run_name=f\"claude_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"CLAUDE\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e938ac2-5206-432e-bd8e-2597c1bc2998",
   "metadata": {
    "language": "python",
    "name": "add_runs"
   },
   "outputs": [],
   "source": "mistral_run = tru_rag_mistral.add_run(run_config=mistral_run_config)\n\nllama_run = tru_rag_llama.add_run(run_config=llama_run_config)\n\nclaude_run = tru_rag_claude.add_run(run_config=claude_run_config)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62e0bccb-5975-4481-b923-163b07798734",
   "metadata": {
    "language": "python",
    "name": "start_mistral_run"
   },
   "outputs": [],
   "source": "mistral_run.start(input_df=batch_data)\nprint(\"Finished mistral run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e66f72b7-75cf-4fb6-a55e-02e7284a2c02",
   "metadata": {
    "language": "python",
    "name": "start_llama_run"
   },
   "outputs": [],
   "source": "llama_run.start(input_df=batch_data)\nprint(\"Finished Llama run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4644e4fe-7732-4665-a227-64f6dbd6058a",
   "metadata": {
    "language": "python",
    "name": "start_claude_run"
   },
   "outputs": [],
   "source": "claude_run.start(input_df=batch_data)\nprint(\"Finished Claude run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61207bef-6726-41e3-8b34-0857f15f7171",
   "metadata": {
    "language": "python",
    "name": "check_run_status_1"
   },
   "outputs": [],
   "source": "print(f\"Mistral: {mistral_run.get_status()}\")\nprint(f\"Llama: {llama_run.get_status()}\")\nprint(f\"Claude: {claude_run.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a76affd9-0862-4ff3-be08-25851e84ed11",
   "metadata": {
    "language": "python",
    "name": "run_mistral_metrics"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nmistral_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4eb42a44-9155-40cf-86ec-542195b7e608",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nllama_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4652f34d-b709-4440-9e51-bfdc6bee96ed",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nclaude_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fbca118f-e0a8-4969-9527-d381ab7d86ba",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "print(f\"Mistral: {mistral_run.get_status()}\")\nprint(f\"Llama: {llama_run.get_status()}\")\nprint(f\"Claude: {claude_run.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738df93c-8b06-43ef-9824-a9c1c209339a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "generate_ai_obs_UI_link"
   },
   "outputs": [],
   "source": "import streamlit as st\n\norg_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\naccount_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\ndb_name = session.sql('SELECT CURRENT_DATABASE()').collect()[0][0]\nschema_name = session.sql('SELECT CURRENT_SCHEMA()').collect()[0][0]\n\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/ai-evaluations/databases/{db_name}/schemas/{schema_name}/applications/{app_name.upper()}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d40c5-249b-4989-8cc3-9ec329c9c90d",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "AIObsApplication"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/AIObsApp.jpg\", decompress=False).read() \n",
    "\n",
    "# Display the image\n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc402ee-ac04-41ef-9b64-b623b4a66d93",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "Summary"
   },
   "outputs": [],
   "source": [
    "image1=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/Anthropic.jpg\", decompress=False).read() \n",
    "st.image(image1, width=800)\n",
    "image2=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/Summary2.jpg\", decompress=False).read() \n",
    "st.image(image2, width=800)"
   ]
  }
 ]
}
