{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "lastEditStatus": {
   "notebookId": "asp3rxthn6aurbcbxqcu",
   "authorId": "5095547476787",
   "authorName": "EBOTWICK",
   "authorEmail": "elliott.botwick@snowflake.com",
   "sessionId": "8a7944b9-1c50-499c-8aae-4ddbb5e8b71e",
   "lastEditTime": 1746655212248
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "a1ee390b-c216-4c30-9cef-15e61b5a1acd",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\n\nimport snowflake.core\nfrom snowflake.snowpark import Session\nfrom snowflake.core import Root\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.cortex import complete\n\nfrom typing import List\nimport os\nimport sys\nimport json\nimport time\n\n#Set up snowflake session vars and env vars\nsession = get_active_session()\nroot = Root(session)\n\nos.environ[\"TRULENS_OTEL_TRACING\"] = \"1\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86161c8a-fa0a-46b2-8368-a279c00be836",
   "metadata": {
    "language": "python",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "DB_NAME = \"SUMMIT_25_AI_OBS_DEMO\"\nSCHEMA_NAME = \"DATA\"\nSTAGE_NAME = \"DOCS\"\nWH_NAME = \"COMPUTE_WH\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf34a-f360-4223-bff2-60f016ff6c3e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "CortexSearchRetrieverCell",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Access cortex search retriever built in 1st notebook\nt1 = time.time()\ntest_query = \"What is the performance of Cortex Search?\"\n\n\ncortex_search_service = (\n    root\n    .databases[DB_NAME]\n    .schemas[SCHEMA_NAME]\n    .cortex_search_services[\"SNOWFLAKE_BLOG_RETRIEVAL\"]\n)\nresp = cortex_search_service.search(\n    query=test_query,\n    columns=[\"SEARCH_COL\"],\n    limit=10,\n    experimental={\"returnConfidenceScores\": True}\n)\nt2 = time.time()\n\nf_time = 1000*(t2 - t1)\nprint(f\"Execution time: {f_time:.2f} milliseconds\")\n\nsearch_results = [row[\"SEARCH_COL\"] for row in resp.results] if resp.results else []\n\nsearch_results"
  },
  {
   "cell_type": "code",
   "id": "fbb7b4d4-a9ca-4c0e-b812-f54004e13eb9",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "#Filter out resuls with confidence score below a set confidence_score_threshold\nconfidence_score_threshold = 1\nfiltered_results = list(filter(lambda x: int(x['@CONFIDENCE_SCORE']) >=confidence_score_threshold, resp.results))\ncontext_chunks = list(map(lambda x: x['SEARCH_COL'], filtered_results))\n\ncontext_chunks",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b17a5544-5275-4795-8b02-3d0c0103c781",
   "metadata": {
    "language": "python",
    "name": "cell10",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Below code is 50x slower (1 ms instead of 0.02 but a little cleaner)\nt1 = time.time()\n\n[d['SEARCH_COL'] for d in resp.results if int(d['@CONFIDENCE_SCORE']) >= 2]\n\nt2 = time.time()\n\nf_time = 1000*(t2 - t1)\n\nprint(f\"Execution time: {f_time:.2f} milliseconds\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c33f1ee0-70ef-442e-a9fc-8e4bce620946",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "respo = requests.get('https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-analyst/custom-instructions').text\n# .content.decode('utf-8')\nsoupo = BeautifulSoup(respo, 'html.parser')\n\n# Get all text content\ntext_content = soupo.get_text(separator='\\n', strip=True)\ntext_content.split('Â¶')",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2c59837e-7f41-4af3-9129-f0a7a59e1f0f",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "import requests\nfrom bs4 import BeautifulSoup\n\ndef search_snow_docs(query):\n    try:\n        #Define URL and get links\n        url = f\"https://docs.snowflake.com/search?q={query}\"\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n        \n        #set up bs4 and get all links from search result page\n        soup = BeautifulSoup(response.text, 'html.parser')\n        links = [a.get('href') for a in soup.find_all('a', href=True) if a.get('href').startswith(\"https://\")]\n        try:\n            links.remove('https://docs.snowflake.com')\n            links.remove('https://status.snowflake.com')\n            links.remove('https://other-docs.snowflake.com/en/opencatalog/overview')\n        except:\n            pass\n        return requests.get(links[0].content)\n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching URL: {e}\")\n        return []\n    \n\nall_links = search_snow_docs(\"Cortex Analyst Custom instructions\")\n\nif all_links:\n    for link in all_links:\n        print(link)\nelse:\n    print(\"No links found or an error occurred.\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a8cd62c5-b74e-462c-91a9-b269e2a95d43",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b51fe4-118c-437c-a348-462d2fb25f58",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "DefineRAGClass"
   },
   "outputs": [],
   "source": "# Create the RAGWithObservability class to structure the RAG pipeline\nfrom snowflake.cortex import complete\nfrom trulens.core.otel.instrument import instrument\nfrom trulens.otel.semconv.trace import SpanAttributes\n\n\nclass RAGWithObservability():\n    def __init__(self, llm_model, retriever):\n        self.llm_model = llm_model\n        self.retriever = retriever\n        \n#Here we're using the @instrument decorator to trace various stages of our RAG applicaiton\n    @instrument (\n        span_type=SpanAttributes.SpanType.RETRIEVAL, \n        attributes={\n            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n        })  \n    def retrieve_context(self, query: str) -> List[str]:\n        return self.retriever.retrieve(query)\n\n    @instrument()\n    def augment_prompt(self, query: str, contexts: list) -> str:\n     \n        prompt = f\"\"\"\n        You are an expert assistant extracting information from context provided.\n        Answer the question based on the context. Be concise and do not hallucinate.\n        If you don't have the information, just say so.\n        Context: {' '.join(contexts)}\n        Question: {query}\n        Answer:\n        \"\"\"\n        return prompt\n\n\n    @instrument (span_type=SpanAttributes.SpanType.GENERATION)    \n    def generate_completion(self, query: str):\n        \n        df_response = complete(self.llm_model, query)\n        return df_response\n\n\n    @instrument (\n        span_type=SpanAttributes.SpanType.RECORD_ROOT, \n        attributes={\n            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n        })\n    def query_app(self, query: str) -> str:\n        contexts = self.retrieve_context(query)\n        prompt = self.augment_prompt(query, contexts)\n        final_response = self.generate_completion(prompt)\n        return final_response"
  },
  {
   "cell_type": "code",
   "id": "8467e565-8611-49e3-b259-b53c21a9f7ff",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "import streamlit as st\n\n#Define LLM classes\nllama_rag = RAGWithObservability('llama3.1-8b', retriever)\nmistral7b_rag = RAGWithObservability('mistral-7b', retriever)\nclaude_rag = RAGWithObservability('claude-3-5-sonnet', retriever)\n\n#print Query\nprint(f\"Query: {test_query}\")\n\n#Get and print responses\nllama_response = llama_rag.query_app(test_query)\nst.write(f\"**Llama response** -  {llama_response} \\n\")\n\nmistral_response = mistral7b_rag.query_app(test_query)\nst.write(f\"**Mistral-7b response** - {mistral_response} \\n\")\n\nclaude_response = claude_rag.query_app(test_query)\nst.write(f\"**Claude response** -  {claude_response} \\n\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5b33b25-20c3-4cd7-9dce-118400be593c",
   "metadata": {
    "collapsed": false,
    "name": "Step6"
   },
   "source": "## Step 6: Observe and Evaluate LLM Performance with AI Observability (powered by TruLens)\n\n**Adding Observability and Evaluataion to our RAG application**\n\nHere, we enhance the Retrieval-Augmented Generation (RAG) process by introducing observability. Observability ensures that LLM responses can be measured and evaluated based on various feedback metrics, providing insights into the model's performance and areas for improvement.\n\n**How This Works**\n\nWe will use a feature called AI Observability to register our recently created applications in Snowflake. This will allow users to pass in prompts to these applications, and trace each step the application takes to Retrieve appropriate context, Augment a system prompt with additional context and Generate a complete answer for the given prompt. \n\nFrom there we will use LLM-as-a-Judge based evaluations to measure LLM performance based on **feedback metrics** including:\n- **Answer Relevance** - Evaluates how directly the LLM's response addresses the user's prompt.\n- **Context Relevance** - Assesses the relevance of the retrieved context to the user's prompt.\n- **Groundedness**  - Measures how well the LLM's response is anchored in the retrieved context.\n- **Coherance** - Evaluates how logically structured and easy to follow the LLM's response is."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13d6db-55d3-4841-8915-1088cab39a45",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "AIObservability"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/AIObservability.jpg\", decompress=False).read() \n",
    "\n",
    "# Display the image\n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58d853-417c-4d46-abfd-6c928613a45f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "LLMObservabilitySetup"
   },
   "outputs": [],
   "source": "# from trulens.core import TruSession\nfrom trulens.apps.app import TruApp\nfrom trulens.connectors.snowflake import SnowflakeConnector\n\ntru_snowflake_connector = SnowflakeConnector(snowpark_session=session)\n\napp_name = \"test_sko_app_update\"\nversion_num = 'v0'\n\ntru_rag_mistral = TruApp(\n    mistral7b_rag,\n    app_name=app_name,\n    app_version=f\"mistral_test_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_llama = TruApp(\n    llama_rag,\n    app_name=app_name,\n    app_version=f\"llama_test_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_claude = TruApp(\n    claude_rag,\n    app_name=app_name,\n    app_version=f\"claude_test_{version_num}\",\n    connector=tru_snowflake_connector\n)"
  },
  {
   "cell_type": "code",
   "id": "239dd11c-5b9a-40f9-a115-39692c06ed05",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "import pandas as pd\n\nprompts = [\n    \"What are some metrics to measure the quality of a retrieval system?\",\n    \"Can I have a back-and-forth conversation with Cortex?\",\n    \"Does Snowflake support text-to-sql? What services would support this?\",\n    \"What year was the war of 1812?\",\n    \"Tell me a story about Snowflake Cortex\"\n]\n\n\nbatch_data = pd.DataFrame({'QUERY': prompts})\nbatch_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e86306d7-b0a9-4d12-af47-f881228d7d9d",
   "metadata": {
    "language": "python",
    "name": "define_run_configs"
   },
   "outputs": [],
   "source": "from trulens.core.run import Run\nfrom trulens.core.run import RunConfig\n\nmistral_run_config = RunConfig(\n    run_name=f\"mistral_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"MISTRAL\",\n    llm_judge_name = \"llama3.1-70b\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n)\n\n\n\nllama_run_config = RunConfig(\n    run_name=f\"llama_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LLAMA\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)\n\n\nclaude_run_config = RunConfig(\n    run_name=f\"claude_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"CLAUDE\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e938ac2-5206-432e-bd8e-2597c1bc2998",
   "metadata": {
    "language": "python",
    "name": "add_runs"
   },
   "outputs": [],
   "source": "mistral_run = tru_rag_mistral.add_run(run_config=mistral_run_config)\n\nllama_run = tru_rag_llama.add_run(run_config=llama_run_config)\n\nclaude_run = tru_rag_claude.add_run(run_config=claude_run_config)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62e0bccb-5975-4481-b923-163b07798734",
   "metadata": {
    "language": "python",
    "name": "start_mistral_run"
   },
   "outputs": [],
   "source": "mistral_run.start(input_df=batch_data)\nprint(\"Finished mistral run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e66f72b7-75cf-4fb6-a55e-02e7284a2c02",
   "metadata": {
    "language": "python",
    "name": "start_llama_run"
   },
   "outputs": [],
   "source": "llama_run.start(input_df=batch_data)\nprint(\"Finished Llama run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4644e4fe-7732-4665-a227-64f6dbd6058a",
   "metadata": {
    "language": "python",
    "name": "start_claude_run"
   },
   "outputs": [],
   "source": "claude_run.start(input_df=batch_data)\nprint(\"Finished Claude run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61207bef-6726-41e3-8b34-0857f15f7171",
   "metadata": {
    "language": "python",
    "name": "check_run_status_1"
   },
   "outputs": [],
   "source": "print(f\"Mistral: {mistral_run.get_status()}\")\nprint(f\"Llama: {llama_run.get_status()}\")\nprint(f\"Claude: {claude_run.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a76affd9-0862-4ff3-be08-25851e84ed11",
   "metadata": {
    "language": "python",
    "name": "run_mistral_metrics"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nmistral_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4eb42a44-9155-40cf-86ec-542195b7e608",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nllama_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4652f34d-b709-4440-9e51-bfdc6bee96ed",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nclaude_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fbca118f-e0a8-4969-9527-d381ab7d86ba",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "print(f\"Mistral: {mistral_run.get_status()}\")\nprint(f\"Llama: {llama_run.get_status()}\")\nprint(f\"Claude: {claude_run.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738df93c-8b06-43ef-9824-a9c1c209339a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "generate_ai_obs_UI_link"
   },
   "outputs": [],
   "source": "import streamlit as st\n\norg_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\naccount_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\ndb_name = session.sql('SELECT CURRENT_DATABASE()').collect()[0][0]\nschema_name = session.sql('SELECT CURRENT_SCHEMA()').collect()[0][0]\n\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/ai-evaluations/databases/{db_name}/schemas/{schema_name}/applications/{app_name.upper()}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d40c5-249b-4989-8cc3-9ec329c9c90d",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "AIObsApplication"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/AIObsApp.jpg\", decompress=False).read() \n",
    "\n",
    "# Display the image\n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc402ee-ac04-41ef-9b64-b623b4a66d93",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "Summary"
   },
   "outputs": [],
   "source": [
    "image1=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/Anthropic.jpg\", decompress=False).read() \n",
    "st.image(image1, width=800)\n",
    "image2=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/Summary2.jpg\", decompress=False).read() \n",
    "st.image(image2, width=800)"
   ]
  }
 ]
}