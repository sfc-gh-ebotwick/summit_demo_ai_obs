{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "lastEditStatus": {
   "notebookId": "asp3rxthn6aurbcbxqcu",
   "authorId": "5095547476787",
   "authorName": "EBOTWICK",
   "authorEmail": "elliott.botwick@snowflake.com",
   "sessionId": "8a7944b9-1c50-499c-8aae-4ddbb5e8b71e",
   "lastEditTime": 1746679775340
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "a1ee390b-c216-4c30-9cef-15e61b5a1acd",
   "metadata": {
    "language": "python",
    "name": "python_import"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\n\nimport snowflake.core\nfrom snowflake.snowpark import Session\nfrom snowflake.core import Root\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.cortex import complete\n\nfrom typing import List\nimport os\nimport sys\nimport json\nimport time\nimport requests\nfrom bs4 import BeautifulSoup\n\n#Set up snowflake session vars and env vars\nsession = get_active_session()\nroot = Root(session)\n\nos.environ[\"TRULENS_OTEL_TRACING\"] = \"1\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86161c8a-fa0a-46b2-8368-a279c00be836",
   "metadata": {
    "language": "python",
    "name": "define_vars",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "DB_NAME = \"SUMMIT_25_AI_OBS_DEMO\"\nSCHEMA_NAME = \"DATA\"\nSTAGE_NAME = \"DOCS\"\nWH_NAME = \"COMPUTE_WH\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf34a-f360-4223-bff2-60f016ff6c3e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "CortexSearchRetriever",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Access cortex search retriever built in 1st notebook\ntest_query = \"What is the performance of Cortex Search?\"\n\n\ncortex_search_service = (\n    root\n    .databases[DB_NAME]\n    .schemas[SCHEMA_NAME]\n    .cortex_search_services[\"SNOWFLAKE_BLOG_RETRIEVAL\"]\n)\nresp = cortex_search_service.search(\n    query=test_query,\n    columns=[\"SEARCH_COL\"],\n    limit=10,\n    experimental={\"returnConfidenceScores\": True}\n)\n\nsearch_results = [row[\"SEARCH_COL\"] for row in resp.results] if resp.results else []\n\nsearch_results"
  },
  {
   "cell_type": "code",
   "id": "2c59837e-7f41-4af3-9129-f0a7a59e1f0f",
   "metadata": {
    "language": "python",
    "name": "search_snow_docs_function"
   },
   "outputs": [],
   "source": "def search_snow_docs(query):\n    try:\n        #Define URL and get links\n        url = f\"https://docs.snowflake.com/search?q={query}\"\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n        \n        #set up bs4 and get all links from search result page\n        link_soup = BeautifulSoup(response.text, 'html.parser')\n        links = [a.get('href') for a in link_soup.find_all('a', href=True) if a.get('href').startswith(\"https://\")]\n\n        #Remove extra links that are on search results page but not relevant to results\n        try:\n            links.remove('https://docs.snowflake.com')\n            links.remove('https://status.snowflake.com')\n            links.remove('https://other-docs.snowflake.com/en/opencatalog/overview')\n        except:\n            pass\n\n\n        # links\n        try:\n            #Get content from first web page in list\n            web_page_soup = BeautifulSoup(requests.get(links[0]).text, 'html.parser')\n            \n            # Extract the title\n            title = web_page_soup.title.string if web_page_soup.title else \"No Title Found\"\n            \n            # Initialize the markdown output\n            markdown_output = f\"# {title}\\n\\n\"\n            # Find all headers and paragraphs together\n            elements = web_page_soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'pre', 'code', 'table'])\n\n            # Iterate through the elements, preserving the order\n            for element in elements:\n                if element.name.startswith('h'):  # If it's a header (h1, h2, etc.)\n                    markdown_output += f\"## {element.get_text()}\\n\\n\"\n                else:  # If it's a paragraph\n                    markdown_output += f\"{element.get_text()}\\n\\n\"\n    \n            return markdown_output\n        except: \n               return \"No web page content found!\"\n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching URL: {e}\")\n        return []",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d8f0f2f-d000-4755-9b3e-fcf916cc8cd3",
   "metadata": {
    "language": "python",
    "name": "retrieval_fusion_function"
   },
   "outputs": [],
   "source": "def context_retrieval(user_query, confidence_score_threshold):\n\n    #First call cortex search service on knowledgebase!\n    \n    css_response = cortex_search_service.search(\n        query=user_query,\n        columns=[\"SEARCH_COL\"],\n        limit=10,\n        experimental={\"returnConfidenceScores\": True})\n    \n    filtered_results = list(filter(lambda x: int(x['@CONFIDENCE_SCORE']) >=confidence_score_threshold, \n                                   css_response.results))\n    context_chunks = list(map(lambda x: x['SEARCH_COL'], filtered_results))\n\n    #If no results from knowledgebase, do a websearch on snowflake docs and truncate results to 10000 chars\n    if len(context_chunks)==0:\n        print(\"No results found in knowledgebase! Performing search on docs.snowflake.com...\")\n        #Call function to do search on snowflake docs (\n        context_chunks.append(search_snow_docs(user_query)[0:10000])\n    else:\n        print(f\"Found {len(context_chunks)} relevant context chunks in the knowledgebase!\")\n    return context_chunks",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93f9fe64-98e5-45c1-ac3f-feeb74b205e0",
   "metadata": {
    "language": "python",
    "name": "test_retriever"
   },
   "outputs": [],
   "source": "test_chunks = context_retrieval(user_query = \"Are there any Cortex Search customers?\", \n                  confidence_score_threshold=3)\n\ntest_chunks",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f47d787f-703c-4a88-a1d2-3afc1746969a",
   "metadata": {
    "language": "python",
    "name": "testing_confidence_scores"
   },
   "outputs": [],
   "source": "q = \"Who are some cortex analyst customers\"\n\ncss_response = cortex_search_service.search(\n    query=q,\n    columns=[\"SEARCH_COL\"],\n    limit=10,\n    experimental={\"returnConfidenceScores\": True})\n\nfiltered_results = list(filter\n                        (lambda x: json.loads(x['@DEBUG_PER_RESULT'])['ConfidenceScoreUnrounded'] >=1.8, \n                               css_response.results))\n\nfiltered_results",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b51fe4-118c-437c-a348-462d2fb25f58",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "DefineRAGClass",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Create the RAGWithObservability class to structure the RAG pipeline\nfrom snowflake.cortex import complete\nfrom trulens.core.otel.instrument import instrument\nfrom trulens.otel.semconv.trace import SpanAttributes\n\n\nclass RAGWithObservability():\n    def __init__(self, llm_model):\n        self.llm_model = llm_model\n        # self.retriever = retriever\n\n#Here we're using the @instrument decorator to trace various stages of our RAG applicaiton\n\n#WEB SEARCH FUNCTION\n    @instrument()\n    def search_snow_docs(self, query):\n        try:\n            #Define URL and get links\n            url = f\"https://docs.snowflake.com/search?q={query}\"\n            response = requests.get(url)\n            response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n            \n            #set up bs4 and get all links from search result page\n            link_soup = BeautifulSoup(response.text, 'html.parser')\n            links = [a.get('href') for a in link_soup.find_all('a', href=True) if a.get('href').startswith(\"https://\")]\n    \n            #Remove extra links that are on search results page but not relevant to results\n            try:\n                links.remove('https://docs.snowflake.com')\n                links.remove('https://status.snowflake.com')\n                links.remove('https://other-docs.snowflake.com/en/opencatalog/overview')\n            except:\n                pass\n    \n    \n            # links\n            try:\n                #Get content from first web page in list\n                web_page_soup = BeautifulSoup(requests.get(links[0]).text, 'html.parser')\n                \n                # Extract the title\n                title = web_page_soup.title.string if web_page_soup.title else \"No Title Found\"\n                \n                # Initialize the markdown output\n                markdown_output = f\"# {title}\\n\\n\"\n                # Find all headers and paragraphs together\n                elements = web_page_soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'pre', 'code', 'table'])\n    \n                # Iterate through the elements, preserving the order\n                for element in elements:\n                    if element.name.startswith('h'):  # If it's a header (h1, h2, etc.)\n                        markdown_output += f\"## {element.get_text()}\\n\\n\"\n                    else:  # If it's a paragraph\n                        markdown_output += f\"{element.get_text()}\\n\\n\"\n        \n                return markdown_output\n            except: \n                   return \"No web page content found!\"\n        except requests.exceptions.RequestException as e:\n            print(f\"Error fetching URL: {e}\")\n            return []\n\n#RETRIEVEL FUNCTION\n    \n    @instrument (\n        span_type=SpanAttributes.SpanType.RETRIEVAL, \n        attributes={\n            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n        })  \n    def retrieve_context(self, query: str, confidence_score_threshold=2):\n    \n        #First call cortex search service on knowledgebase!\n        \n        css_response = cortex_search_service.search(\n            query=query,\n            columns=[\"SEARCH_COL\"],\n            limit=10,\n            experimental={\"returnConfidenceScores\": True})\n        \n        filtered_results = list(filter(lambda x: int(x['@CONFIDENCE_SCORE']) >=confidence_score_threshold, \n                                       css_response.results))\n        context_chunks = list(map(lambda x: x['SEARCH_COL'], filtered_results))\n    \n        #If no results from knowledgebase, do a websearch on snowflake docs and truncate results to 10000 chars\n        if len(context_chunks)==0:\n            print(\"No results found in knowledgebase! Performing search on docs.snowflake.com...\")\n            #Call function to do search on snowflake docs (\n            context_chunks.append(self.search_snow_docs(query)[0:10000])\n        else:\n            print(f\"Found {len(context_chunks)} relevant context chunks in the knowledgebase!\")\n        return context_chunks\n\n#PROMPT AUGMENTATION FUNCTION\n\n    @instrument()\n    def augment_prompt(self, query: str, contexts: list) -> str:\n     \n        prompt = f\"\"\"\n        You are an expert assistant extracting information from context provided.\n        Answer the question based on the context. Be concise and do not hallucinate.\n        If you don't have the information, just say so.\n        Context: {' '.join(contexts)}\n        Question: {query}\n        Answer:\n        \"\"\"\n        return prompt\n\n#COMPLETION FUNCTION\n\n    @instrument (span_type=SpanAttributes.SpanType.GENERATION)    \n    def generate_completion(self, query: str):\n        \n        df_response = complete(self.llm_model, query)\n        return df_response\n\n#ROOT FUNCTION\n    @instrument (\n        span_type=SpanAttributes.SpanType.RECORD_ROOT, \n        attributes={\n            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n        })\n    def query_app(self, query: str) -> str:\n        contexts = self.retrieve_context(query)\n        prompt = self.augment_prompt(query, contexts)\n        final_response = self.generate_completion(prompt)\n        return final_response"
  },
  {
   "cell_type": "code",
   "id": "8467e565-8611-49e3-b259-b53c21a9f7ff",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "import streamlit as st\n\ntest_query = \"Is cortex analyst public preview or GA?\"\n\n#Define LLM classes\nllama_rag = RAGWithObservability('llama4-maverick')\nmistral7b_rag = RAGWithObservability('mistral-7b')\ndeepseek_rag = RAGWithObservability('deepseek-r1')\n\n#print Query\nprint(f\"Query: {test_query}\")\n\n#Get and print responses\nllama_response = llama_rag.query_app(test_query)\nst.write(f\"**Llama response** -  {llama_response} \\n\")\n\nmistral_response = mistral7b_rag.query_app(test_query)\nst.write(f\"**Mistral-7b response** - {mistral_response} \\n\")\n\ndeepseek_response = deepseek_rag.query_app(test_query)\nst.write(f\"**Deepseek response** -  {deepseek_response} \\n\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58d853-417c-4d46-abfd-6c928613a45f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "LLMObservabilitySetup"
   },
   "outputs": [],
   "source": "# from trulens.core import TruSession\nfrom trulens.apps.app import TruApp\nfrom trulens.connectors.snowflake import SnowflakeConnector\n\ntru_snowflake_connector = SnowflakeConnector(snowpark_session=session)\n\napp_name = \"DEV_SUMMIT_AI_OPS\"\nversion_num = 'v0'\n\ntru_rag_mistral = TruApp(\n    mistral7b_rag,\n    app_name=app_name,\n    app_version=f\"MISTRAL_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_llama = TruApp(\n    llama_rag,\n    app_name=app_name,\n    app_version=f\"LLAMA_{version_num}\",\n    connector=tru_snowflake_connector\n)"
  },
  {
   "cell_type": "code",
   "id": "239dd11c-5b9a-40f9-a115-39692c06ed05",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "import pandas as pd\n\nprompts = [\n    \"How does Cortex Search work?\",\n    \"What components of Cortex Analyst are in Preview vs GA?\",\n    \"Can I have a multiturn conversation with Cortex?\",\n    \"What are some best practices to consider using Custom Instructions in Cortex Analayst?\",\n    \"How does Markaasz benefit from Cortex Search?\",\n    \"Who uses DocAI?\",\n    \"Can you help me purchase a new refridgerator?\",\n    \"Who is the product manager\"\n]\n\nbatch_data = pd.DataFrame({'QUERY': prompts})\nbatch_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e86306d7-b0a9-4d12-af47-f881228d7d9d",
   "metadata": {
    "language": "python",
    "name": "define_run_configs"
   },
   "outputs": [],
   "source": "from trulens.core.run import Run\nfrom trulens.core.run import RunConfig\n\nmistral_run_config = RunConfig(\n    run_name=f\"mistral_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"MISTRAL\",\n    llm_judge_name = \"llama3.1-70b\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n)\n\n\n\nllama_run_config = RunConfig(\n    run_name=f\"llama_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LLAMA\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e938ac2-5206-432e-bd8e-2597c1bc2998",
   "metadata": {
    "language": "python",
    "name": "add_runs"
   },
   "outputs": [],
   "source": "mistral_run = tru_rag_mistral.add_run(run_config=mistral_run_config)\n\nllama_run = tru_rag_llama.add_run(run_config=llama_run_config)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62e0bccb-5975-4481-b923-163b07798734",
   "metadata": {
    "language": "python",
    "name": "start_mistral_run"
   },
   "outputs": [],
   "source": "mistral_run.start(input_df=batch_data)\nprint(\"Finished mistral run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e66f72b7-75cf-4fb6-a55e-02e7284a2c02",
   "metadata": {
    "language": "python",
    "name": "start_llama_run"
   },
   "outputs": [],
   "source": "llama_run.start(input_df=batch_data)\nprint(\"Finished Llama run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61207bef-6726-41e3-8b34-0857f15f7171",
   "metadata": {
    "language": "python",
    "name": "check_run_status_1"
   },
   "outputs": [],
   "source": "print(f\"Mistral: {mistral_run.get_status()}\")\nprint(f\"Llama: {llama_run.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a76affd9-0862-4ff3-be08-25851e84ed11",
   "metadata": {
    "language": "python",
    "name": "run_mistral_metrics"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nmistral_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4eb42a44-9155-40cf-86ec-542195b7e608",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nllama_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fbca118f-e0a8-4969-9527-d381ab7d86ba",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "print(f\"Mistral: {mistral_run.get_status()}\")\nprint(f\"Llama: {llama_run.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738df93c-8b06-43ef-9824-a9c1c209339a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "generate_ai_obs_UI_link"
   },
   "outputs": [],
   "source": "import streamlit as st\n\norg_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\naccount_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\ndb_name = session.sql('SELECT CURRENT_DATABASE()').collect()[0][0]\nschema_name = session.sql('SELECT CURRENT_SCHEMA()').collect()[0][0]\n\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/ai-evaluations/databases/{db_name}/schemas/{schema_name}/applications/{app_name.upper()}')"
  },
  {
   "cell_type": "markdown",
   "id": "ad0d40c5-249b-4989-8cc3-9ec329c9c90d",
   "metadata": {
    "name": "ARCHIVE_BELOW",
    "collapsed": false
   },
   "source": "# ARCHIVE BELOW"
  },
  {
   "cell_type": "code",
   "id": "bbb959f7-9133-4f4a-b08d-980eb6ce3987",
   "metadata": {
    "language": "python",
    "name": "timing_code"
   },
   "outputs": [],
   "source": "t1 = time.time()\n\nt2 = time.time()\n\nf_time = 1000*(t2 - t1)\nprint(f\"Execution time: {f_time:.2f} milliseconds\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d17d07e-0a44-4288-8571-26d7f5159e51",
   "metadata": {
    "language": "python",
    "name": "filter_low_confidence_results"
   },
   "outputs": [],
   "source": "#Filter out resuls with confidence score below a set confidence_score_threshold\nconfidence_score_threshold = 3\nfiltered_results = list(filter(lambda x: int(x['@CONFIDENCE_SCORE']) >=confidence_score_threshold, resp.results))\ncontext_chunks = list(map(lambda x: x['SEARCH_COL'], filtered_results))\n\ncontext_chunks\n\n# Below code is 50x slower (1 ms instead of 0.02 but a little cleaner)\n\n#context_chunks_list= [d['SEARCH_COL'] for d in resp.results if int(d['@CONFIDENCE_SCORE']) >= 2]",
   "execution_count": null
  }
 ]
}