{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "lastEditStatus": {
   "notebookId": "kycawgs3v4o5yso5rrlj",
   "authorId": "5095547476787",
   "authorName": "EBOTWICK",
   "authorEmail": "elliott.botwick@snowflake.com",
   "sessionId": "d5f10746-f3e3-4a24-8232-11c6c7e189cc",
   "lastEditTime": 1747972211196
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "a1ee390b-c216-4c30-9cef-15e61b5a1acd",
   "metadata": {
    "language": "python",
    "name": "python_import"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\n\nimport snowflake.core\nfrom snowflake.snowpark import Session\nfrom snowflake.core import Root\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.cortex import complete\n\nfrom typing import List\nimport os\nimport sys\nimport json\nimport time\nimport requests\nfrom bs4 import BeautifulSoup\n\n#Set up snowflake session vars and env vars\nsession = get_active_session()\nroot = Root(session)\n\n#Enable OpenTelemetry Tracing\nos.environ[\"TRULENS_OTEL_TRACING\"] = \"1\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "86161c8a-fa0a-46b2-8368-a279c00be836",
   "metadata": {
    "language": "python",
    "name": "define_vars",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "DB_NAME = \"SUMMIT_AI_OBS_DEMO\"\nSCHEMA_NAME = \"DATA\"\nSTAGE_NAME = \"DOCS\"\nWH_NAME = \"AI_OBS_WAREHOUSE\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf34a-f360-4223-bff2-60f016ff6c3e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "CortexSearchRetriever",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#Access cortex search retriever built in 1st notebook\ntest_query = \"How can I asses the performance of Cortex Search?\"\n\n\ncortex_search_service = (\n    root\n    .databases[DB_NAME]\n    .schemas[SCHEMA_NAME]\n    .cortex_search_services[\"SNOWFLAKE_BLOG_RETRIEVAL\"]\n)\nresp = cortex_search_service.search(\n    query=test_query,\n    columns=[\"SEARCH_COL\"],\n    limit=5,\n    experimental={\"returnConfidenceScores\": True}\n)\n\nsearch_results = [(f\"Confidence Score: {row['@CONFIDENCE_SCORE']}/3\", row[\"SEARCH_COL\"]) for row in resp.results] if resp.results else []\n\nsearch_results\n"
  },
  {
   "cell_type": "code",
   "id": "2c59837e-7f41-4af3-9129-f0a7a59e1f0f",
   "metadata": {
    "language": "python",
    "name": "search_snow_docs_function",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def search_snow_docs(query):\n    try:\n        #Define URL and get links\n        url = f\"https://docs.snowflake.com/search?q={query}\"\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n        \n        #set up bs4 and get all links from search result page\n        link_soup = BeautifulSoup(response.text, 'html.parser')\n        links = [a.get('href') for a in link_soup.find_all('a', href=True) if a.get('href').startswith(\"https://\")]\n\n        #Remove extra links that are on search results page but not relevant to results\n        try:\n            links.remove('https://docs.snowflake.com')\n            links.remove('https://status.snowflake.com')\n            links.remove('https://other-docs.snowflake.com/en/opencatalog/overview')\n        except:\n            pass\n\n\n        # links\n        try:\n            #Get content from first web page in list\n            web_page_soup = BeautifulSoup(requests.get(links[0]).text, 'html.parser')\n            \n            # Extract the title\n            title = web_page_soup.title.string if web_page_soup.title else \"No Title Found\"\n            \n            # Initialize the markdown output\n            markdown_output = f\"# {title}\\n\\n\"\n            # Find all headers and paragraphs together\n            elements = web_page_soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'pre', 'code', 'table'])\n\n            # Iterate through the elements, preserving the order\n            for element in elements:\n                if element.name.startswith('h'):  # If it's a header (h1, h2, etc.)\n                    markdown_output += f\"## {element.get_text()}\\n\\n\"\n                else:  # If it's a paragraph\n                    markdown_output += f\"{element.get_text()}\\n\\n\"\n    \n            return markdown_output\n        except: \n               return \"No web page content found!\"\n    except requests.exceptions.RequestException as e:\n        print(f\"Error fetching URL: {e}\")\n        return []",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4d8f0f2f-d000-4755-9b3e-fcf916cc8cd3",
   "metadata": {
    "language": "python",
    "name": "retrieval_fusion_function",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def context_retrieval(user_query, confidence_score_threshold):\n\n    #First call cortex search service on knowledgebase!\n    \n    css_response = cortex_search_service.search(\n        query=user_query,\n        columns=[\"SEARCH_COL\"],\n        limit=10,\n        experimental={\"returnConfidenceScores\": True})\n    \n    filtered_results = list(filter(lambda x: int(x['@CONFIDENCE_SCORE']) >=confidence_score_threshold, \n                                   css_response.results))\n    context_chunks = list(map(lambda x: x['SEARCH_COL'], filtered_results))\n\n    #If no results from knowledgebase, do a websearch on snowflake docs and truncate results to 10000 chars\n    if len(context_chunks)==0:\n        print(\"No results found in knowledgebase! Performing search on docs.snowflake.com...\")\n        #Call function to do search on snowflake docs (\n        context_chunks.append(search_snow_docs(user_query)[0:10000])\n    else:\n        print(f\"Found {len(context_chunks)} relevant context chunks in the knowledgebase!\")\n    return context_chunks",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93f9fe64-98e5-45c1-ac3f-feeb74b205e0",
   "metadata": {
    "language": "python",
    "name": "test_retriever",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\ntest_query = \"What are best practices using Custom Instructions in Cortex Analyst?\"\ntest_threshold = 3\n\n\ntest_chunks = context_retrieval(user_query = test_query, confidence_score_threshold=test_threshold)\n\nfor i in test_chunks:\n    with st.expander(label = \"Context\",expanded=False):\n        st.write(i)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b51fe4-118c-437c-a348-462d2fb25f58",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "DefineRAGClass",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# Create the RAGWithObservability class to structure the RAG pipeline\nfrom snowflake.cortex import complete\nfrom trulens.core.otel.instrument import instrument\nfrom trulens.otel.semconv.trace import SpanAttributes\n\n\nclass RAG():\n    def __init__(self, llm_model, use_web_search):\n        self.llm_model = llm_model\n        self.use_web_search = use_web_search\n\n#Here we're using the @instrument decorator to trace various stages of our RAG applicaiton\n\n#WEB SEARCH FUNCTION\n    @instrument()\n    def search_snow_docs(self, query):\n        try:\n            #Define URL and get links\n            url = f\"https://docs.snowflake.com/search?q={query}\"\n            response = requests.get(url)\n            response.raise_for_status()  # Raise an HTTPError for bad responses (4xx or 5xx)\n            \n            #set up bs4 and get all links from search result page\n            link_soup = BeautifulSoup(response.text, 'html.parser')\n            \n            #Get all links that start with https:// on the page and are not in subset of non-result links that we don't want\n            non_result_links = ['https://docs.snowflake.com', 'https://status.snowflake.com', 'https://other-docs.snowflake.com/en/opencatalog/overview']\n            links = [a.get('href') for a in link_soup.find_all('a', href=True) \n                     if (a.get('href').startswith(\"https://\") and a.get('href') not in non_result_links)]\n    \n    \n            # links\n            try:\n                #Get content from first web page in list\n                web_page_soup = BeautifulSoup(requests.get(links[0]).text, 'html.parser')\n                \n                # Extract the title\n                title = web_page_soup.title.string if web_page_soup.title else \"No Title Found\"\n                \n                # Initialize the markdown output\n                markdown_output = f\"# {title}\\n\\n\"\n                # Find all headers and paragraphs together\n                elements = web_page_soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'p', 'pre', 'code', 'table'])\n    \n                # Iterate through the elements, preserving the order\n                for element in elements:\n                    if element.name.startswith('h'):  # If it's a header (h1, h2, etc.)\n                        markdown_output += f\"## {element.get_text()}\\n\\n\"\n                    else:  # If it's a paragraph/code/table\n                        markdown_output += f\"{element.get_text()}\\n\\n\"\n        \n                return markdown_output\n            except: \n                   st.write(\"No content found!\")\n                   return \"No content found!\"\n        except requests.exceptions.RequestException as e:\n            st.write(f\"Error fetching URL: {e}\")\n            return []\n\n#RETRIEVEL FUNCTION\n    \n    @instrument (\n        span_type=SpanAttributes.SpanType.RETRIEVAL, \n        attributes={\n            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n        })  \n    def retrieve_context(self, query: str, confidence_score_threshold=2):\n    \n        #First call cortex search service on knowledgebase!\n        \n        css_response = cortex_search_service.search(\n            query=query,\n            columns=[\"SEARCH_COL\"],\n            limit=10,\n            experimental={\"returnConfidenceScores\": True})\n        \n        filtered_results = list(filter(lambda x: int(x['@CONFIDENCE_SCORE']) >=confidence_score_threshold, \n                                       css_response.results))\n        context_chunks = list(map(lambda x: x['SEARCH_COL'], filtered_results))\n    \n        #If no results from knowledgebase and web search is enabled - do a websearch on snowflake docs and truncate results to 10000 chars\n        if len(context_chunks)==0 and self.use_web_search:\n            st.warning(\"No results found in knowledgebase! Performing search on docs.snowflake.com...\")\n            #Call function to do search on snowflake docs (\n            context_chunks.append(self.search_snow_docs(query)[0:10000])\n        elif len(context_chunks)==0:\n            context_chunks.append(\"No results found in knowledgebase and web search disabled!\")\n            st.error(\"No results found in knowledgebase and web search disabled!\")\n        else:\n            st.success(f\"Found {len(context_chunks)} relevant context chunks in the knowledgebase!\")\n        return context_chunks\n\n#PROMPT AUGMENTATION FUNCTION\n\n    @instrument()\n    def augment_prompt(self, query: str, contexts: list) -> str:\n     \n        prompt = f\"\"\"\n        You are an expert assistant extracting information from context provided.\n        Answer the question based on the context. Be concise and do not hallucinate.\n        If you don't have the information, just say so.\n        Context: {' '.join(contexts)}\n        Question: {query}\n        Answer:\n        \"\"\"\n        return prompt\n\n#COMPLETION FUNCTION\n\n    @instrument (span_type=SpanAttributes.SpanType.GENERATION)    \n    def generate_completion(self, query: str):\n        \n        df_response = complete(self.llm_model, query)\n        return df_response\n\n#ROOT FUNCTION\n    @instrument (\n        span_type=SpanAttributes.SpanType.RECORD_ROOT, \n        attributes={\n            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n        })\n    def query_app(self, query: str) -> str:\n        st.write(query)\n        contexts = self.retrieve_context(query)\n        prompt = self.augment_prompt(query, contexts)\n        final_response = self.generate_completion(prompt)\n        st.write(final_response)\n        return final_response"
  },
  {
   "cell_type": "code",
   "id": "8467e565-8611-49e3-b259-b53c21a9f7ff",
   "metadata": {
    "language": "python",
    "name": "test_apps",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\n\ntest_query = \"What is cortex search?\"\n\n#Define LLM classes\nllama_web_rag = RAG(llm_model='llama3.1-8b', use_web_search=True)\nmistral7b_web_rag = RAG(llm_model = 'mistral-7b', use_web_search=True)\n\n# With web search agent disabled\nllama_rag = RAG(llm_model='llama3.1-8b', use_web_search=False)\nmistral7b_rag = RAG(llm_model = 'mistral-7b', use_web_search=False)\n\n#Get and print results\nst.write(\"LLAMA\")\nllama_response = llama_rag.query_app(test_query)\n\nst.write(\"MISTRAL\")\nmistral_response = mistral7b_rag.query_app(test_query)\n\n\nst.write(\"LLAMA WEB\")\nllama_response = llama_web_rag.query_app(test_query)\n\nst.write(\"MISTRAL WEB\")\nmistral_response = mistral7b_web_rag.query_app(test_query)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58d853-417c-4d46-abfd-6c928613a45f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "LLMObservabilitySetup",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "# from trulens.core import TruSession\nfrom trulens.apps.app import TruApp\nfrom trulens.connectors.snowflake import SnowflakeConnector\n\ntru_snowflake_connector = SnowflakeConnector(snowpark_session=session)\n\napp_name = \"AI_OBS_AGENT_RAG_DEMO\"\nversion_num = 'v0'\n\ntru_rag_mistral = TruApp(\n    mistral7b_rag,\n    app_name=app_name,\n    app_version=f\"MISTRAL_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_llama = TruApp(\n    llama_rag,\n    app_name=app_name,\n    app_version=f\"LLAMA_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_mistral_web = TruApp(\n    mistral7b_web_rag,\n    app_name=app_name,\n    app_version=f\"WEB_MISTRAL_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_llama_web = TruApp(\n    llama_web_rag,\n    app_name=app_name,\n    app_version=f\"WEB_LLAMA_{version_num}\",\n    connector=tru_snowflake_connector\n)"
  },
  {
   "cell_type": "code",
   "id": "239dd11c-5b9a-40f9-a115-39692c06ed05",
   "metadata": {
    "language": "python",
    "name": "define_prompts",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\n\nprompts = [\n    \"How does Cortex Search work?\",\n    \"What components of Cortex Analyst are in Preview vs GA?\",\n    \"Can I have a multiturn conversation with Cortex?\",\n    \"What was TSI's total ROI from using Snowflake Cortex?\",\n    \"What are some best practices to consider using Custom Instructions in Cortex Analayst?\",\n    \"How does Markaasz benefit from Cortex Search?\",\n    \"Can you help me purchase a new refridgerator?\",\n    \"What are benefits of using DocAI?\",\n    \"What are some best practices for using Snowflake's feature store?\",\n    \"What is snowflake time travel?\"\n\n    \n]\n\nbatch_data = pd.DataFrame({'QUERY': prompts})\nbatch_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e86306d7-b0a9-4d12-af47-f881228d7d9d",
   "metadata": {
    "language": "python",
    "name": "define_run_configs",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from trulens.core.run import Run\nfrom trulens.core.run import RunConfig\n\nrun_version = version_num\n\nmistral_run_config = RunConfig(\n    run_name=f\"mistral_run_{run_version}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LOCAL\",\n    llm_judge_name = \"llama3.1-70b\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n)\n\n\n\nllama_run_config = RunConfig(\n    run_name=f\"llama_run_{run_version}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LOCAL\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)\n\n\nweb_mistral_run_config = RunConfig(\n    run_name=f\"mistral_web_run_{run_version}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"WEB\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n)\n\n\n\nweb_llama_run_config = RunConfig(\n    run_name=f\"llama_web_run_{run_version}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"WEB\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e938ac2-5206-432e-bd8e-2597c1bc2998",
   "metadata": {
    "language": "python",
    "name": "add_runs",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "mistral_run = tru_rag_mistral.add_run(run_config=mistral_run_config)\nllama_run = tru_rag_llama.add_run(run_config=llama_run_config)\n\nweb_mistral_run = tru_rag_mistral_web.add_run(run_config=web_mistral_run_config)\nweb_llama_run = tru_rag_llama_web.add_run(run_config=web_llama_run_config)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62e0bccb-5975-4481-b923-163b07798734",
   "metadata": {
    "language": "python",
    "name": "start_mistral_run",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "mistral_run.start(input_df=batch_data)\nprint(\"Finished mistral run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e66f72b7-75cf-4fb6-a55e-02e7284a2c02",
   "metadata": {
    "language": "python",
    "name": "start_llama_run",
    "codeCollapsed": false,
    "collapsed": true
   },
   "outputs": [],
   "source": "llama_run.start(input_df=batch_data)\nprint(\"Finished Llama run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f5ded99c-9662-4977-87e6-4451afdff40f",
   "metadata": {
    "language": "python",
    "name": "start_llama_web",
    "codeCollapsed": false,
    "collapsed": true
   },
   "outputs": [],
   "source": "web_llama_run.start(input_df=batch_data)\nprint(\"Finished Llama run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11e95d48-b649-43f9-9fb5-c666b89e4ae6",
   "metadata": {
    "language": "python",
    "name": "start_mistral_web_run",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "web_mistral_run.start(input_df=batch_data)\nprint(\"Finished Llama run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61207bef-6726-41e3-8b34-0857f15f7171",
   "metadata": {
    "language": "python",
    "name": "check_run_status_1",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "run_list = [mistral_run, llama_run, web_mistral_run, web_llama_run]\n\nfor i in run_list:\n    print(f\"{i.run_name} Run Status: {i.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a76affd9-0862-4ff3-be08-25851e84ed11",
   "metadata": {
    "language": "python",
    "name": "compute_eval_metrics",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nfor i in run_list:\n    while i.get_status() == \"INVOCATION_IN_PROGRESS\":\n        time.sleep(3)\n    if i.get_status() == \"INVOCATION_COMPLETED\":\n        i.compute_metrics([\"coherence\",\n                           \"answer_relevance\",\n                           \"context_relevance\",\n                           \"groundedness\"])\n        print(f\"Kicked off Metrics Computation for Run {i.run_name}\")\n    if i.get_status() in [\"FAILED\", \"UNKNOWN\"]:\n        print(\"Not able to compute metrics! Run status:\", i.get_status())\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738df93c-8b06-43ef-9824-a9c1c209339a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "generate_ai_obs_UI_link",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import streamlit as st\n\norg_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\naccount_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\ndb_name = session.sql('SELECT CURRENT_DATABASE()').collect()[0][0]\nschema_name = session.sql('SELECT CURRENT_SCHEMA()').collect()[0][0]\n\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/ai-evaluations/databases/{db_name}/schemas/{schema_name}/applications/{app_name.upper()}')"
  },
  {
   "cell_type": "markdown",
   "id": "ad0d40c5-249b-4989-8cc3-9ec329c9c90d",
   "metadata": {
    "name": "ARCHIVE_BELOW",
    "collapsed": false
   },
   "source": "# ARCHIVE BELOW"
  },
  {
   "cell_type": "code",
   "id": "d867346f-8d51-4460-ac0d-fc836aac0276",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "## Optional Cleanup\n# for i in run_list:\n#     i.delete()",
   "execution_count": null
  }
 ]
}