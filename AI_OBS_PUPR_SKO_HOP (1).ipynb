{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "lastEditStatus": {
   "notebookId": "qubbouvpslvoe6boilqt",
   "authorId": "5095547476787",
   "authorName": "EBOTWICK",
   "authorEmail": "elliott.botwick@snowflake.com",
   "sessionId": "fbbe18e3-a871-4c7c-8930-cba0a1c7712d",
   "lastEditTime": 1743781662556
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "name": "Title",
    "resultHeight": 311
   },
   "source": "# ❄️ SKO RAG HOP - Snowflake Cortex with Anthropic and LLM Observability ❄️\n\nThis notebook demonstrates how to create a Retrieval-Augmented Generation (RAG) workflow in Snowflake using Cortex Search Services, integrate Anthropic LLMs like Claude 3.5, and evaluate responses with new LLM Observability features. Below is an overview of the flow and its key components.\n\n### Step 1: Parse and Chunk Text from PDFs (BUILD)\n### Step 2: Create Cortex Search Service (RETRIEVE)\n### Step 3: Test Search Results with Experimental Configurations (AUGMENT)\n### Step 4: Pass Retrieved Content to LLMs (GENERATE)\n### Step 5: Create RAG Application Class (SERVE)\n### Step 6: Observe and Evaluate LLM Performance with AI Observability (EVALUATE)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "Flow",
    "resultHeight": 87
   },
   "outputs": [],
   "source": [
    "# Import necessary functions\n",
    "import streamlit as st\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/Flow.jpg\", decompress=False).read() \n",
    "\n",
    "# Display the image\n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "Libraries",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "import snowflake.snowpark as snowpark\n",
    "\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64842e12-1e4c-423b-a568-376102123485",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "ViewStage",
    "resultHeight": 426
   },
   "outputs": [],
   "source": [
    "-- List files in the stage to identify PDFs\n",
    "LS @SKO_SKORAGHOP_LIVE_PROD.HOP.RAG;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25663e4-08a0-418c-a6d4-96e913aef549",
   "metadata": {
    "collapsed": false,
    "name": "Step1"
   },
   "source": [
    "## Step 1: Parse and Chunk Text from PDFs\n",
    "We begin by parsing the content of uploaded PDFs and chunking the text using Snowflake's [PARSED_TEXT](https://docs.snowflake.com/sql-reference/functions/parse_document-snowflake-cortex) and [SPLIT_TEXT_RECURSIVE_CHARACTER](https://docs.snowflake.com/sql-reference/functions/split_text_recursive_character-snowflake-cortex) features. These steps structure the text into manageable segments optimized for retrieval. To ensure that the PDF parsing and chunking have been processed correctly, we run queries on the parsed and chunked tables. This step helps verify the integrity of the content.\n",
    "\n",
    "Objective: **Transform unstructured content into indexed chunks for efficient search and retrieval.**\n",
    "\n",
    "Key Outputs:\n",
    "- SKO.HOP.PARSED_TEXT: Table containing the raw text.\n",
    "- SKO.HOP.CORTEX_CHUNK: Chunked, searchable content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f293bf7-06b5-4d05-9666-ad3096d25a31",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "CreateParsedTextTable",
    "resultHeight": 111
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (579301450.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    -- Create a table to hold the extracted text from the PDF files loaded in the SKO.HOP.RAG stage\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "-- Create a table to hold the extracted text from the PDF files loaded in the SKO_SKORAGHOP_LIVE_PROD.HOP.RAG stage\n",
    "\n",
    "-- Complete the missing code (???) to use create a table called PARSED_TEXT\n",
    "\n",
    "CREATE OR REPLACE TABLE SKO_SKORAGHOP_LIVE_PROD.HOP.PARSED_TEXT (relative_path VARCHAR(500), raw_text VARIANT);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e7c0b-6c8f-472f-9cfe-94e1351b9925",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "UseParseDocument",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "-- Use Snowflake's new PARSED_TEXT feature to extract the text from the PDFs loaded in @SKO_SKORAGHOP_LIVE_PROD.HOP.RAG stage\n",
    "-- Cortex PARSE_DOCUMENT documentation link is https://docs.snowflake.com/sql-reference/functions/parse_document-snowflake-cortex\n",
    "\n",
    "-- Complete the missing code (???) to:\n",
    "---- Insert into your newly created PARSED_TEXT table\n",
    "---- Use Cortex PARSE_DOCUMENT feature and layout mode\n",
    "\n",
    "INSERT INTO SKO_SKORAGHOP_LIVE_PROD.HOP.PARSED_TEXT (relative_path, raw_text)\n",
    "WITH pdf_files AS (\n",
    "    SELECT DISTINCT\n",
    "        METADATA$FILENAME AS relative_path\n",
    "    FROM @SKO_SKORAGHOP_LIVE_PROD.HOP.RAG\n",
    "    WHERE METADATA$FILENAME ILIKE '%.pdf'\n",
    "      -- Exclude files that have already been parsed\n",
    "      AND METADATA$FILENAME NOT IN (SELECT relative_path FROM PARSED_TEXT)\n",
    ")\n",
    "SELECT \n",
    "    relative_path,\n",
    "    SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n",
    "        '@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG',  -- Your stage name\n",
    "        relative_path,  -- File path\n",
    "        {'mode': 'layout'}  -- Adjust mode as needed ('layout', 'ocr')\n",
    "    ) AS raw_text\n",
    "FROM pdf_files;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2fe17b-9580-43b4-8b23-fb61a695df6c",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "ViewParsedText"
   },
   "outputs": [],
   "source": [
    "-- check the RAW_TEXT to ensure the PDF was parsed as expected\n",
    "-- Complete the missing code (???) to check the RAW_TEXT to ensure the PDF was parsed as expected\n",
    "\n",
    "SELECT *, SNOWFLAKE.CORTEX.COUNT_TOKENS('mistral-7b', RAW_TEXT) as token_count\n",
    "FROM SKO_SKORAGHOP_LIVE_PROD.HOP.PARSED_TEXT;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce5839-f0eb-4d4f-838e-9b3633979c8c",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "TestingSplitTextFunction",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "-- Use Snowflake's new SPLIT_TEXT_RECURSIVE_CHARACTER feature to chunk parsed text from the PDFs loaded in @SKO_SKORAGHOP_LIVE_PROD.HOP.RAG stage\n",
    "-- Cortex SPLIT_TEXT_RECURSIVE_CHARACTER documentation link is https://docs.snowflake.com/sql-reference/functions/split_text_recursive_character-snowflake-cortex\n",
    "\n",
    "-- Complete the missing code (???) to:\n",
    "---- Create a new table called CORTEX_CHUNK to hold the chunked text from your PDF documents\n",
    "---- Use Cortex SPLIT_TEXT_RECURSIVE_CHARACTER feature with a 2000 chunk size and 100 overlap size\n",
    "\n",
    "CREATE OR REPLACE TABLE SKO_SKORAGHOP_LIVE_PROD.HOP.CORTEX_CHUNK AS\n",
    "WITH text_chunks AS (\n",
    "    SELECT\n",
    "        relative_path,\n",
    "        SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER(\n",
    "            raw_text:content::STRING,  -- Extract the 'content' field from the JSON\n",
    "            'markdown', -- Adjust to 'markdown' if needed\n",
    "            2000,       -- Adjust chunk size\n",
    "            100,        -- Adjust overlap size\n",
    "            ['\\n\\n']    -- Adjust separators\n",
    "        ) AS chunks\n",
    "    FROM SKO_SKORAGHOP_LIVE_PROD.HOP.PARSED_TEXT\n",
    ")\n",
    "SELECT\n",
    "    relative_path,\n",
    "    c.value AS chunk  -- Extract each chunk of the parsed text\n",
    "FROM text_chunks,\n",
    "LATERAL FLATTEN(INPUT => chunks) c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64cfb61-0168-43ea-9a70-8242dc45ec07",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "ViewChunkedText",
    "resultHeight": 438
   },
   "outputs": [],
   "source": [
    "-- check the CORTEX_CHUNK to ensure the PDF was chunked as expected\n",
    "-- Complete the missing code (???) to check the CORTEX_CHUNK to ensure the PDF was chunked as expected for the PDF called \"RAGWithoutAugmentation.pdf\"\n",
    "\n",
    "SELECT *, SNOWFLAKE.CORTEX.COUNT_TOKENS('mistral-7b', CHUNK) as token_count\n",
    "FROM SKO_SKORAGHOP_LIVE_PROD.HOP.CORTEX_CHUNK \n",
    "WHERE RELATIVE_PATH ILIKE 'RAGWithoutAugmentation.pdf';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856f350-86ea-42e9-baf1-5da4165e73ef",
   "metadata": {
    "collapsed": false,
    "name": "Step2"
   },
   "source": [
    "## Step 2: Create Cortex Search Service\n",
    "Next, we create a [Cortex Search Service](https://docs.snowflake.com/LIMITEDACCESS/cortex-search/cortex-search-overview#overview) that enables retrieval of relevant text chunks for any query. This service uses the CHUNK column from the chunked table as the indexed content.\n",
    "\n",
    "Purpose: **Index and search chunked content to support the RAG pipeline.**\n",
    "\n",
    "Command:\n",
    "```sql\n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE SKO.HOP.RAG_SEARCH_SERVICE ON SEARCH_COL WAREHOUSE = COMPUTE_WH TARGET_LAG = '1 day' AS SELECT  ...;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe16397-d999-4901-b434-43681a0579b8",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "CortexSearch"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/CortexSearch.jpg\", decompress=False).read() \n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a330f9-c774-47f2-b8ca-031ae441c602",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "CreateCortexSearchService",
    "resultHeight": 111
   },
   "outputs": [],
   "source": "-- Create a search service over your new chunked pdf table that has one searchable text\n-- Cortex Search Service documentation link is https://docs.snowflake.com/LIMITEDACCESS/cortex-search/cortex-search-overview#overview\n\n-- Complete the missing code (???) to:\n---- Create a search service called SKO_SKORAGHOP_LIVE_PROD.HOP.RAG_SEARCH_SERVICE to run over your new chunked pdf table\n---- Queries to the service will search on a new column called SEARCH_COL \n---- Use an x-small warehouse\n---- Use a target_lag of 365 days\n---- SEARCH_COL is the name of the concatenation of RELATIVE_PATH and CHUNK from the CORTEX_CHUNK table\n\nCREATE OR REPLACE CORTEX SEARCH SERVICE SKO_SKORAGHOP_LIVE_PROD.HOP.RAG_SEARCH_SERVICE\n    ON SEARCH_COL\n    WAREHOUSE = EBOTWICK\n    TARGET_LAG = '365 days'\n    AS SELECT \n        RELATIVE_PATH,\n        CHUNK,\n    (RELATIVE_PATH || ' ' || CHUNK) AS SEARCH_COL\nFROM SKO_SKORAGHOP_LIVE_PROD.HOP.CORTEX_CHUNK;"
  },
  {
   "cell_type": "markdown",
   "id": "348e3271-b238-465f-995c-3c8f1df0cf2b",
   "metadata": {
    "collapsed": false,
    "name": "Step3"
   },
   "source": [
    "## Step 3: Test Search Results with Experimental Configurations\n",
    "We will now evaluate [Snowflake Cortex Experimental Knobs](https://docs.google.com/document/d/1HkHtDiY3CmzpSewCe_s9fpMNE5spOUvNSwr6CxFerqE/edit?usp=sharing) to fine-tune the retrieval service and analyze confidence scores and result rankings across configurations. These tests focus on boosting, recency, headers, and reranking to optimize search relevance.\n",
    "\n",
    "**Configurations Tested:**\n",
    "- **Boosted vs. Unboosted:** Compare the impact of keyword emphasis on rankings and scores.\n",
    "- **Time-Based Decays:** Test how prioritizing recent documents affects relevance.\n",
    "- **Header Boosts:** Evaluate the influence of structured headers (e.g., Markdown) on ranking.\n",
    "- **Reranked vs. Non-Reranked:** Analyze trade-offs between query latency and search quality.\n",
    "\n",
    "**Key Metrics:**\n",
    "- **Confidence Scores:** Global relevance scores (0–3) for each result.\n",
    "- **Result Rankings:** Position changes reveal the effectiveness of configurations.\n",
    "\n",
    "By testing these configurations, we aim to enhance Cortex Search Service performance for specific use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e406ce-4f72-4fd5-8360-fc85e10c73bc",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "CortexSearchEnhancements"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/CortexSearchEnhancements.jpg\", decompress=False).read() \n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c8762e-0ebb-4aa7-8a2a-d4af9cbba828",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "TestCortexSearchExperimentalKnobs"
   },
   "outputs": [],
   "source": [
    "-- This query compares Cortex Search Service results across multiple experimental settings: \n",
    "---- boosted (using softBoosts), header boosted, and unboosted (default settings).\n",
    "\n",
    "-- The results are presented side by side to analyze the impact of each configuration on confidence scores and document ranking for matching search columns.\n",
    "-- This analysis helps evaluate the effectiveness of boosting and decay strategies in improving search relevance and recency-based ranking.\n",
    "\n",
    "-- Missing code (???) has been completed to:\n",
    "---- Call the SKO_SKORAGHOP_LIVE_PROD.HOP.RAG_SEARCH_SERVICE to test experimental configurations.\n",
    "---- Use the query: \"How can I augment my LLM prompts with relevant context in Snowpark?\"\n",
    "---- For the boosted_results section, apply softBoosts using the phrases \"Augment\" and \"RAG.\"\n",
    "---- Enable returnConfidenceScores to true for all configurations.\n",
    "\n",
    "WITH boosted_results AS (\n",
    "    SELECT DISTINCT\n",
    "        VALUE:\"SEARCH_COL\"::STRING AS SearchColumn,\n",
    "        VALUE:\"@CONFIDENCE_SCORE\"::STRING AS ConfidenceScore\n",
    "    FROM (\n",
    "        SELECT PARSE_JSON(\n",
    "            SNOWFLAKE.CORTEX.SEARCH_PREVIEW(\n",
    "                'SKO_SKORAGHOP_LIVE_PROD.HOP.RAG_SEARCH_SERVICE',\n",
    "                '{\n",
    "                    \"query\": \"How can I augment my llm prompts with relevant context in snowpark?\",\n",
    "                    \"limit\": 3,\n",
    "                    \"experimental\": {\n",
    "                        \"softBoosts\": [\n",
    "                            { \"phrase\": \"Augment\" },\n",
    "                            { \"phrase\": \"RAG\" }\n",
    "                        ],\n",
    "                        \"reranker\": \"none\",\n",
    "                        \"returnConfidenceScores\": true\n",
    "                    }\n",
    "                }'\n",
    "            )\n",
    "        ) AS boosted_json\n",
    "    ),\n",
    "    LATERAL FLATTEN(input => boosted_json:\"results\")\n",
    "),\n",
    "header_boosted_results AS (\n",
    "    SELECT DISTINCT\n",
    "        VALUE:\"SEARCH_COL\"::STRING AS SearchColumn,\n",
    "        VALUE:\"@CONFIDENCE_SCORE\"::STRING AS ConfidenceScore\n",
    "    FROM (\n",
    "        SELECT PARSE_JSON(\n",
    "            SNOWFLAKE.CORTEX.SEARCH_PREVIEW(\n",
    "                'SKO_SKORAGHOP_LIVE_PROD.HOP.RAG_SEARCH_SERVICE',\n",
    "                '{\n",
    "                    \"query\": \"How can I augment my llm prompts with relevant context in snowpark?\",\n",
    "                    \"limit\": 3,\n",
    "                    \"experimental\": {\n",
    "                        \"headerBoost\": {\n",
    "                            \"multiplier\": 2,\n",
    "                            \"skipStopWords\": true\n",
    "                        },\n",
    "                        \"reranker\": \"none\",\n",
    "                        \"returnConfidenceScores\": true\n",
    "                    }\n",
    "                }'\n",
    "            )\n",
    "        ) AS header_boosted_json\n",
    "    ),\n",
    "    LATERAL FLATTEN(input => header_boosted_json:\"results\")\n",
    "),\n",
    "unboosted_results AS (\n",
    "    SELECT DISTINCT\n",
    "        VALUE:\"SEARCH_COL\"::STRING AS SearchColumn,\n",
    "        VALUE:\"@CONFIDENCE_SCORE\"::STRING AS ConfidenceScore\n",
    "    FROM (\n",
    "        SELECT PARSE_JSON(\n",
    "            SNOWFLAKE.CORTEX.SEARCH_PREVIEW(\n",
    "                'SKO_SKORAGHOP_LIVE_PROD.HOP.RAG_SEARCH_SERVICE',\n",
    "                '{\n",
    "                    \"query\": \"How can I augment my llm prompts with relevant context in snowpark?\",\n",
    "                    \"limit\": 3,\n",
    "                    \"experimental\": {\n",
    "                        \"returnConfidenceScores\": true\n",
    "                    }\n",
    "                }'\n",
    "            )\n",
    "        ) AS unboosted_json\n",
    "    ),\n",
    "    LATERAL FLATTEN(input => unboosted_json:\"results\")\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(b.SearchColumn, hb.SearchColumn, u.SearchColumn) AS SearchColumn,\n",
    "    b.ConfidenceScore AS BoostedConfidenceScore,\n",
    "    hb.ConfidenceScore AS HeaderBoostedConfidenceScore,\n",
    "    u.ConfidenceScore AS UnboostedConfidenceScore\n",
    "FROM\n",
    "    boosted_results b\n",
    "FULL OUTER JOIN header_boosted_results hb\n",
    "    ON b.SearchColumn = hb.SearchColumn\n",
    "FULL OUTER JOIN unboosted_results u\n",
    "    ON COALESCE(b.SearchColumn, hb.SearchColumn) = u.SearchColumn\n",
    "ORDER BY \n",
    "    CASE WHEN BoostedConfidenceScore IS NULL THEN 1 ELSE 0 END, \n",
    "    BoostedConfidenceScore DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859c78c-4bd3-4bf6-b355-68f357830b74",
   "metadata": {
    "collapsed": false,
    "name": "Step4"
   },
   "source": [
    "## Step 4: Pass Retrieved Content to LLMs\n",
    "This step demonstrates how to pass retrieved contextual content to various LLMs using the Snowflake Cortex [`COMPLETE`](https://docs.snowflake.com/en/sql-reference/functions/complete-snowflake-cortex) function. The process includes:\n",
    "\n",
    "- **Retrieving Contextual Information**: Context is fetched from the search service.\n",
    "- **Generating Structured Prompts**: The retrieved context is injected into prompts for LLMs.\n",
    "- **LLM Interaction**: Prompts are passed to models like `mistral-7b`, `mistral-large2`, and `Anthropic Claude 3.5` for response generation.\n",
    "- **Comparative Analysis**: Model outputs are compared for quality, relevance, and coherence.\n",
    "\n",
    "Example Query:\n",
    "```sql\n",
    "SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "    'claude-3-5-sonnet',\n",
    "    CONCAT('Your context: ', (SELECT LISTAGG(CHUNK, ' ') FROM searchresults))\n",
    ") AS RESPONSE\n",
    "FROM searchresults;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c541d-c305-47f4-96c5-64c7c8dfba92",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "AddCortexComplete"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/CortexSearch_Complete.jpg\", decompress=False).read() \n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605f5809-2ca9-4908-9d1a-1ad6fba7db29",
   "metadata": {
    "collapsed": false,
    "name": "QueryIdeas",
    "resultHeight": 169
   },
   "source": [
    "**Queries to test the capabilities of the LLMs based on the PDF content:**\n",
    "- What is the difference between semantic and lexical searches? Does a hybrid system exist?\n",
    "- How can we optimize context retrieval in retrievel agumented geneartion for an LLM system?\"'\n",
    "- Can I use SQL in Snowflake to retrieve relevant context for my GPT prompt?\n",
    "- What service runs fuzzy-search to retrieve context in Snowflake?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19284d0-107c-4c7f-aa2e-5378159c4a3b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "CheckSearchResults"
   },
   "outputs": [],
   "source": [
    "# Query your Snowflake Cortex Search Service using the Snowpark Python API to retrieve and process search results.\n",
    "\n",
    "# Complete the missing code (???) to:\n",
    "## Specify your database 'SKO_SKORAGHOP_LIVE_PROD', your schema 'HOP', and your Cortex Search Service named 'RAG_SEARCH_SERVICE'\n",
    "## Specify your SEARCH_COL as the column of interest\n",
    "\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.core import Root\n",
    "root = Root(session)\n",
    "\n",
    "transcript_search_service = (root\n",
    "  .databases['SKO_SKORAGHOP_LIVE_PROD']\n",
    "  .schemas['HOP']\n",
    "  .cortex_search_services['RAG_SEARCH_SERVICE']\n",
    ")\n",
    "\n",
    "resp = transcript_search_service.search(\n",
    "  query=\"\"\"How does Snowflake simplify the deployment of retrieval-augmented generation (RAG) workflows?\"\"\",\n",
    "  columns=['SEARCH_COL'],\n",
    "  limit=3\n",
    ")\n",
    "results = resp.results\n",
    "\n",
    "context_str = \"\"\n",
    "for i, r in enumerate(results):\n",
    "    context_str += f\"Context document {i+1}: {r['SEARCH_COL']}\\n****************\\n\"\n",
    "\n",
    "print(context_str)\n",
    "df = session.create_dataframe(resp.results)\n",
    "df.create_or_replace_temp_view(\"searchresults\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f8035-e606-4503-b2cc-3e7b32035cc3",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "AnthropicClaudeSonnetOverview"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/Claude35Sonnet.jpg\", decompress=False).read() \n",
    "\n",
    "# Display the image\n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e31d76d-1106-4527-a059-9cf407fb0a84",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "Test3LLMs",
    "resultHeight": 111
   },
   "outputs": [],
   "source": [
    "-- Create a temporary table with the LLM responses\n",
    "\n",
    "-- Complete the missing code (???) to:\n",
    "---- Create a TEMPORARY table called LLMResults\n",
    "---- Use mistral-7b for the MISTRAL_7B (first model)\n",
    "---- Use mistral-large2 for the MISTRAL_LARGE2 (second model)\n",
    "---- Use the Anthropic model (claude-3-5-sonnet) for the CLAUDE_35 (third model)\n",
    "\n",
    "CREATE OR REPLACE TEMPORARY TABLE LLMResults AS\n",
    "WITH PROMPT_TEXT AS (\n",
    "  SELECT CONCAT(\n",
    "    'You are a helpful AI assistant specialized in assisting Sales Engineers...',\n",
    "    (SELECT LISTAGG(SEARCH_COL, ' ') FROM searchresults),\n",
    "    ' Focus on key points and avoid unnecessary details.'\n",
    "  ) AS P\n",
    ")\n",
    "SELECT \n",
    "   SNOWFLAKE.CORTEX.COMPLETE('mistral-7b', (SELECT P FROM PROMPT_TEXT)) AS MISTRAL_7B,\n",
    "   SNOWFLAKE.CORTEX.COMPLETE('mistral-large2', (SELECT P FROM PROMPT_TEXT)) AS MISTRAL_LARGE2,\n",
    "   SNOWFLAKE.CORTEX.COMPLETE('claude-3-5-sonnet', (SELECT P FROM PROMPT_TEXT)) AS CLAUDE_35;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90ca06-7a03-4d4a-bb81-a6d751c8bc76",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "ViewMistral_7BResults"
   },
   "outputs": [],
   "source": [
    "df = session.sql(\"SELECT * FROM LLMResults\").to_pandas()\n",
    "st.subheader(\"Output for Mistral-7b LLM\")\n",
    "mistral_7b_value = df.iloc[0][\"MISTRAL_7B\"]\n",
    "st.code(mistral_7b_value, language=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f83f15-32a5-4314-bd54-dc5ab4b55089",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "ViewMistralLarge2Result"
   },
   "outputs": [],
   "source": [
    "st.subheader(\"Output for Mistral-Large2 LLM\")\n",
    "mistral_7b_value = df.iloc[0][\"MISTRAL_LARGE2\"]\n",
    "st.code(mistral_7b_value, language=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a7ccc8-1f91-4d9f-af6c-cfc53de0a519",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "ViewAnthropicResult"
   },
   "outputs": [],
   "source": [
    "st.subheader(\"Output for Anthropic Claude 3.5 Sonnet LLM\")\n",
    "claude_rag = df.iloc[0][\"CLAUDE_35\"]\n",
    "st.code(claude_rag, language=\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d45331-c62b-4bb5-b947-77971382483a",
   "metadata": {
    "collapsed": false,
    "name": "Step5"
   },
   "source": [
    "## Step 5: Create RAG Application Classes\n",
    "\n",
    "In this step, we will create two Python classes to build a Retrieval-Augmented Generation (RAG) pipeline:\n",
    "\n",
    "1. **`CortexSearchRetriever`**:\n",
    "   - This class interacts with the Cortex Search Service to retrieve relevant contextual information based on a user query.\n",
    "   - It connects to the Cortex Search Service using Snowflake's `Root` object and performs a search with the specified query and result limit.\n",
    "   - The retrieved context (a list of relevant chunks) will be used to generate prompts for LLMs.\n",
    "\n",
    "2. **`RAGWithObservability`**:\n",
    "   - This class integrates the retrieval functionality with a specified Large Language Model (LLM) to complete the RAG pipeline.\n",
    "   - It uses the retriever to fetch context, creates a structured prompt by combining the context with the user query, and generates a response using the Snowflake Cortex `COMPLETE` function.\n",
    "   - The class allows testing of different LLMs (e.g., `llama3.1-8b`, `mistral-7b`, `claude-3-5-sonnet`) by specifying the desired model.\n",
    "    - In the below cells you'll notice an **@instrument** decorator above each function in our RAGWithObservability class\n",
    "    - This tells Trulens which stages of our application we want to track so we can understand how data flows through our application\n",
    "    - For example if our query takes 10s to run - what portion of that 10s was spent on retrieval? On prompt augmentation? On completion generation?\n",
    "        - This becomes increasingly important for complex GenAI applications (i.e. multi-agent apps)\n",
    "    - After we pass prompts through our trulens recorder we will inspect these traces and spans!\n",
    "\n",
    "### Workflow Summary:\n",
    "1. The `CortexSearchRetriever` retrieves relevant context from the Cortex Search Service.\n",
    "2. The `RAGWithObservability` uses this context to create prompts and generate responses with the specified LLM.\n",
    "\n",
    "These two classes work together to streamline the RAG pipeline, enabling efficient retrieval and response generation for various use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65daf34a-f360-4223-bff2-60f016ff6c3e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "CortexSearchRetrieverCell"
   },
   "outputs": [],
   "source": [
    "# Define the retriever class for interacting with the Cortex Search Service\n",
    "\n",
    "# Complete the missing code (???) to:\n",
    "## Specify your database 'SKO_SKORAGHOP_LIVE_PROD', your schema 'HOP', and your Cortex Search Service named 'RAG_SEARCH_SERVICE'\n",
    "## Specify your SEARCH_COL as the column of interest\n",
    "## Intialize retriever with your CortexSearchRetriever class\n",
    "## Use \"What are some components of the Snowflake Cortex offering? How do they work?\" for the test_query\n",
    "\n",
    "from typing import List\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.core import Root\n",
    "\n",
    "# CortexSearchRetriever\n",
    "class CortexSearchRetriever:\n",
    "    def __init__(self, session: Session, limit_to_retrieve: int = 4):\n",
    "        self._session = session\n",
    "        self._limit_to_retrieve = limit_to_retrieve\n",
    "        \n",
    "\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        root = Root(session)\n",
    "        cortex_search_service = (\n",
    "            root\n",
    "            .databases[\"SKO_SKORAGHOP_LIVE_PROD\"]\n",
    "            .schemas[\"HOP\"]\n",
    "            .cortex_search_services[\"RAG_SEARCH_SERVICE\"]\n",
    "        )\n",
    "        resp = cortex_search_service.search(\n",
    "            query=query,\n",
    "            columns=[\"SEARCH_COL\"],\n",
    "            limit=self._limit_to_retrieve,\n",
    "        )\n",
    "        return [row[\"SEARCH_COL\"] for row in resp.results] if resp.results else []\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = CortexSearchRetriever(session=session, limit_to_retrieve=3)\n",
    "test_query = \"What are some components of the Snowflake Cortex offering? How do they work?\"\n",
    "retrieved_context = retriever.retrieve(query=test_query)\n",
    "print(retrieved_context)"
   ]
  },
  {
   "cell_type": "code",
   "id": "9a349f73-1e07-49dc-8a9d-492626503e01",
   "metadata": {
    "language": "python",
    "name": "set_trulens_OTEL_env_var"
   },
   "outputs": [],
   "source": "import os\nos.environ[\"TRULENS_OTEL_TRACING\"] = \"1\"",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b51fe4-118c-437c-a348-462d2fb25f58",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "DefineRAGClass"
   },
   "outputs": [],
   "source": "# Create the RAGWithObservability class to structure the RAG pipeline\nfrom snowflake.cortex import complete\nfrom trulens.core.otel.instrument import instrument\nfrom trulens.otel.semconv.trace import SpanAttributes\n\n\nclass RAGWithObservability():\n    def __init__(self, llm_model, retriever):\n        self.llm_model = llm_model\n        self.retriever = retriever\n        \n#Here we're using the @instrument decorator to trace various stages of our RAG applicaiton\n    @instrument (\n        span_type=SpanAttributes.SpanType.RETRIEVAL, \n        attributes={\n            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n        })  \n    def retrieve_context(self, query: str) -> List[str]:\n        return self.retriever.retrieve(query)\n\n    @instrument()\n    def augment_prompt(self, query: str, contexts: list) -> str:\n     \n        prompt = f\"\"\"\n        You are an expert assistant extracting information from context provided.\n        Answer the question based on the context. Be concise and do not hallucinate.\n        If you don't have the information, just say so.\n        Context: {' '.join(contexts)}\n        Question: {query}\n        Answer:\n        \"\"\"\n        return prompt\n\n\n    @instrument (span_type=SpanAttributes.SpanType.GENERATION)    \n    def generate_completion(self, query: str):\n        \n        df_response = complete(self.llm_model, query)\n        return df_response\n\n\n    @instrument (\n        span_type=SpanAttributes.SpanType.RECORD_ROOT, \n        attributes={\n            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n        })\n    def query_app(self, query: str) -> str:\n        contexts = self.retrieve_context(query)\n        prompt = self.augment_prompt(query, contexts)\n        final_response = self.generate_completion(prompt)\n        return final_response"
  },
  {
   "cell_type": "code",
   "id": "8467e565-8611-49e3-b259-b53c21a9f7ff",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": "import streamlit as st\n\n#Define LLM classes\nllama_rag = RAGWithObservability('llama3.1-8b', retriever)\nmistral7b_rag = RAGWithObservability('mistral-7b', retriever)\nclaude_rag = RAGWithObservability('claude-3-5-sonnet', retriever)\n\n#print Query\nprint(f\"Query: {test_query}\")\n\n#Get and print responses\nllama_response = llama_rag.query_app(test_query)\nst.write(f\"**Llama response** -  {llama_response} \\n\")\n\nmistral_response = mistral7b_rag.query_app(test_query)\nst.write(f\"**Mistral-7b response** - {mistral_response} \\n\")\n\nclaude_response = claude_rag.query_app(test_query)\nst.write(f\"**Claude response** -  {claude_response} \\n\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5b33b25-20c3-4cd7-9dce-118400be593c",
   "metadata": {
    "collapsed": false,
    "name": "Step6"
   },
   "source": "## Step 6: Observe and Evaluate LLM Performance with AI Observability (powered by TruLens)\n\n**Adding Observability and Evaluataion to our RAG application**\n\nHere, we enhance the Retrieval-Augmented Generation (RAG) process by introducing observability. Observability ensures that LLM responses can be measured and evaluated based on various feedback metrics, providing insights into the model's performance and areas for improvement.\n\n**How This Works**\n\nWe will use a feature called AI Observability to register our recently created applications in Snowflake. This will allow users to pass in prompts to these applications, and trace each step the application takes to Retrieve appropriate context, Augment a system prompt with additional context and Generate a complete answer for the given prompt. \n\nFrom there we will use LLM-as-a-Judge based evaluations to measure LLM performance based on **feedback metrics** including:\n- **Answer Relevance** - Evaluates how directly the LLM's response addresses the user's prompt.\n- **Context Relevance** - Assesses the relevance of the retrieved context to the user's prompt.\n- **Groundedness**  - Measures how well the LLM's response is anchored in the retrieved context.\n- **Coherance** - Evaluates how logically structured and easy to follow the LLM's response is."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13d6db-55d3-4841-8915-1088cab39a45",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "AIObservability"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/AIObservability.jpg\", decompress=False).read() \n",
    "\n",
    "# Display the image\n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b58d853-417c-4d46-abfd-6c928613a45f",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "LLMObservabilitySetup"
   },
   "outputs": [],
   "source": "# from trulens.core import TruSession\nfrom trulens.apps.app import TruApp\nfrom trulens.connectors.snowflake import SnowflakeConnector\n\ntru_snowflake_connector = SnowflakeConnector(snowpark_session=session)\n\napp_name = \"test_sko_app_update\"\nversion_num = 'v0'\n\ntru_rag_mistral = TruApp(\n    mistral7b_rag,\n    app_name=app_name,\n    app_version=f\"mistral_test_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_llama = TruApp(\n    llama_rag,\n    app_name=app_name,\n    app_version=f\"llama_test_{version_num}\",\n    connector=tru_snowflake_connector\n)\n\ntru_rag_claude = TruApp(\n    claude_rag,\n    app_name=app_name,\n    app_version=f\"claude_test_{version_num}\",\n    connector=tru_snowflake_connector\n)"
  },
  {
   "cell_type": "code",
   "id": "239dd11c-5b9a-40f9-a115-39692c06ed05",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "import pandas as pd\n\nprompts = [\n    \"What are some metrics to measure the quality of a retrieval system?\",\n    \"Can I have a back-and-forth conversation with Cortex?\",\n    \"Does Snowflake support text-to-sql? What services would support this?\",\n    \"What year was the war of 1812?\",\n    \"Tell me a story about Snowflake Cortex\"\n]\n\n\nbatch_data = pd.DataFrame({'QUERY': prompts})\nbatch_data",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e86306d7-b0a9-4d12-af47-f881228d7d9d",
   "metadata": {
    "language": "python",
    "name": "define_run_configs"
   },
   "outputs": [],
   "source": "from trulens.core.run import Run\nfrom trulens.core.run import RunConfig\n\nmistral_run_config = RunConfig(\n    run_name=f\"mistral_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"MISTRAL\",\n    llm_judge_name = \"llama3.1-70b\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n)\n\n\n\nllama_run_config = RunConfig(\n    run_name=f\"llama_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"LLAMA\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)\n\n\nclaude_run_config = RunConfig(\n    run_name=f\"claude_exp_{version_num}\",\n    description=\"questions about snowflake AI cababilities\",\n    dataset_name=\"SNOW_RAG_DF1\",\n    source_type=\"DATAFRAME\",\n    label=\"CLAUDE\",\n    dataset_spec={\n        \"RECORD_ROOT.INPUT\": \"QUERY\",\n    },\n    \n)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3e938ac2-5206-432e-bd8e-2597c1bc2998",
   "metadata": {
    "language": "python",
    "name": "add_runs"
   },
   "outputs": [],
   "source": "mistral_run = tru_rag_mistral.add_run(run_config=mistral_run_config)\n\nllama_run = tru_rag_llama.add_run(run_config=llama_run_config)\n\nclaude_run = tru_rag_claude.add_run(run_config=claude_run_config)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62e0bccb-5975-4481-b923-163b07798734",
   "metadata": {
    "language": "python",
    "name": "start_mistral_run"
   },
   "outputs": [],
   "source": "mistral_run.start(input_df=batch_data)\nprint(\"Finished mistral run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e66f72b7-75cf-4fb6-a55e-02e7284a2c02",
   "metadata": {
    "language": "python",
    "name": "start_llama_run"
   },
   "outputs": [],
   "source": "llama_run.start(input_df=batch_data)\nprint(\"Finished Llama run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4644e4fe-7732-4665-a227-64f6dbd6058a",
   "metadata": {
    "language": "python",
    "name": "start_claude_run"
   },
   "outputs": [],
   "source": "claude_run.start(input_df=batch_data)\nprint(\"Finished Claude run\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "61207bef-6726-41e3-8b34-0857f15f7171",
   "metadata": {
    "language": "python",
    "name": "check_run_status_1"
   },
   "outputs": [],
   "source": "print(f\"Mistral: {mistral_run.get_status()}\")\nprint(f\"Llama: {llama_run.get_status()}\")\nprint(f\"Claude: {claude_run.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a76affd9-0862-4ff3-be08-25851e84ed11",
   "metadata": {
    "language": "python",
    "name": "run_mistral_metrics"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nmistral_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4eb42a44-9155-40cf-86ec-542195b7e608",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nllama_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4652f34d-b709-4440-9e51-bfdc6bee96ed",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "#The following code kicks off LLM-as-a-Judge evals for several metrics\n\nclaude_run.compute_metrics([\n    \"coherence\",\n    \"answer_relevance\",\n    \"context_relevance\",\n    \"groundedness\",\n])",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fbca118f-e0a8-4969-9527-d381ab7d86ba",
   "metadata": {
    "language": "python",
    "name": "cell9"
   },
   "outputs": [],
   "source": "print(f\"Mistral: {mistral_run.get_status()}\")\nprint(f\"Llama: {llama_run.get_status()}\")\nprint(f\"Claude: {claude_run.get_status()}\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738df93c-8b06-43ef-9824-a9c1c209339a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "generate_ai_obs_UI_link"
   },
   "outputs": [],
   "source": "import streamlit as st\n\norg_name = session.sql('SELECT CURRENT_ORGANIZATION_NAME()').collect()[0][0]\naccount_name = session.sql('SELECT CURRENT_ACCOUNT_NAME()').collect()[0][0]\ndb_name = session.sql('SELECT CURRENT_DATABASE()').collect()[0][0]\nschema_name = session.sql('SELECT CURRENT_SCHEMA()').collect()[0][0]\n\nst.write(f'https://app.snowflake.com/{org_name}/{account_name}/#/ai-evaluations/databases/{db_name}/schemas/{schema_name}/applications/{app_name.upper()}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d40c5-249b-4989-8cc3-9ec329c9c90d",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "AIObsApplication"
   },
   "outputs": [],
   "source": [
    "# Define image in a stage and read the file\n",
    "image=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/AIObsApp.jpg\", decompress=False).read() \n",
    "\n",
    "# Display the image\n",
    "st.image(image, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc402ee-ac04-41ef-9b64-b623b4a66d93",
   "metadata": {
    "codeCollapsed": true,
    "collapsed": false,
    "language": "python",
    "name": "Summary"
   },
   "outputs": [],
   "source": [
    "image1=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/Anthropic.jpg\", decompress=False).read() \n",
    "st.image(image1, width=800)\n",
    "image2=session.file.get_stream(\"@SKO_SKORAGHOP_LIVE_PROD.HOP.RAG/Summary2.jpg\", decompress=False).read() \n",
    "st.image(image2, width=800)"
   ]
  }
 ]
}